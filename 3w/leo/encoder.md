## word embedding

### glove

- [ratsgo's blog : glove에 대한 설명](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/09/glove/)
- [stanford 배포판](https://nlp.stanford.edu/projects/glove/)
  - whole data : 2.2M
  - wiki 2014 data : 400K

#### tutorials

- [glove 사용법 한글](https://github.com/beyondnlp/nlp/wiki/GLOVE-%EC%82%AC%EC%9A%A9%EB%B2%95-(-Global-Vectors-for-Word-Representation-))

### fast text

- [official](https://fasttext.cc/)
- 일단 설명이 잘되어 있다.
- wiki 2017 data : 1M

#### tutorials

- [using fast text via gensim](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb)
- [loading error solution](https://datascience.stackexchange.com/questions/20071/how-do-i-load-fasttext-pretrained-model-with-gensim)
- [loading gensim function official docs](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.Word2VecKeyedVectors.load_word2vec_format)

## contextual embedding

### elmo

### [ellen nlp](https://allennlp.org/elmo)
