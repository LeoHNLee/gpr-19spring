## word embedding

### glove

- [ratsgo's blog : glove에 대한 설명](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/09/glove/)
- [stanford 배포판](https://nlp.stanford.edu/projects/glove/)
  - whole data : 2.2M
  - wiki 2014 data : 400K

### fast text

- [official](https://fasttext.cc/)
- 일단 설명이 잘되어 있다.
- wiki 2017 data : 1M

## contextual embedding

### elmo

### [ellen nlp](https://allenai.org/)
